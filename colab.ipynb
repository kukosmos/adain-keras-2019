{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izp7T6LROH5p",
        "colab_type": "text"
      },
      "source": [
        "# AdaIN-Keras\n",
        "Keras implementation of [this paper](https://arxiv.org/abs/1703.06868) with [colab](https://colab.research.google.com/).\n",
        "Wrote by [KOSMOS](https://github.com/kukosmos), Korea University programming club.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1nMczBxSkjt",
        "colab_type": "text"
      },
      "source": [
        "You can run this code directly at [here](https://colab.research.google.com/github/kukosmos/adain-keras-2019/blob/master/colab.ipynb) using colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9np-E2Zp4e",
        "colab_type": "text"
      },
      "source": [
        "# 0. Settings & Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TdpU5ebiIDo",
        "colab_type": "text"
      },
      "source": [
        "You can specify the version of tensorflow to use with following command.\n",
        "Following command is the command to select the tensorflow 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1on6KQ-iOEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkBcPfq_URWD",
        "colab_type": "text"
      },
      "source": [
        "These are configurable variables that used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "892vltI4UkDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datas\n",
        "content_path = 'data/coco2017train'\n",
        "style_path = 'data/wikiart'\n",
        "image_size = 512\n",
        "crop_size = 256\n",
        "n_per_epoch = 1000\n",
        "batch_size = 16\n",
        "# loss\n",
        "style_weight = 10.0\n",
        "content_weight =  1.0\n",
        "# optimizer\n",
        "learning_rate = 1e-4\n",
        "learning_rate_decay = 5e-5\n",
        "# log\n",
        "model_dir = 'models/kaiser'\n",
        "# training\n",
        "epochs = 160"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GHF3mg7byZr",
        "colab_type": "text"
      },
      "source": [
        "In this script we will use our implementation of helper methods and classes available in [github](https://github.com/kukosmos/adain-keras-2019)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqh6j5sYaAPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import types\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LDKMI1BaJt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# borrowed from https://stackoverflow.com/a/34491349\n",
        "def import_from_github(uri, name=None):\n",
        "  if not name:\n",
        "    name = os.path.basename(uri).lower().rstrip('.py')\n",
        "  \n",
        "  r = requests.get(uri)\n",
        "  r.raise_for_status()\n",
        "\n",
        "  codeobj = compile(r.content, uri, 'exec')\n",
        "  module = types.ModuleType(name)\n",
        "  exec(codeobj, module.__dict__)\n",
        "  return module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5OPnP1f3WEr",
        "colab_type": "text"
      },
      "source": [
        "This is method for help unformat the formatted string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_V1Sgq43Utk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hC40c2z3SfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# borrowed from https://stackoverflow.com/a/36838374\n",
        "def unformat_string(string, pattern):\n",
        "  regex = re.sub(r'{(.+?)}', r'(?P<_\\1>.+)', pattern)\n",
        "  values = list(re.search(regex, string).groups())\n",
        "  keys = re.findall(r'{(.+?)}', pattern)\n",
        "  return dict(zip(keys, values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMHmaj6PDcC",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k3X_V5RY6jL",
        "colab_type": "text"
      },
      "source": [
        "First, mount the google drive that contains the photos for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtwcHtP8OBl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyndpUoCYpMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0NQXhREYpCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive = Path('/content/drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xTG7R_NY8AL",
        "colab_type": "text"
      },
      "source": [
        "Before creating dataset, configure Pillow to handle errors while loading images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcS7AVuHcpy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrmDlDG0c3NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.MAX_IMAGE_PIXELS = None\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS9F6lQgdLxt",
        "colab_type": "text"
      },
      "source": [
        "Create dataset with content data and style data in your google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNBhjHpbN9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/dataloader.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJnJT2YZeY38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataloader.ContentStyleLoader(\n",
        "  content_root=gdrive / content_path,\n",
        "  content_image_shape=(image_size, image_size),\n",
        "  content_crop='random',\n",
        "  content_crop_size=crop_size,\n",
        "  style_root=gdrive / style_path,\n",
        "  style_image_shape=(image_size, image_size),\n",
        "  style_crop='random',\n",
        "  style_crop_size=crop_size,\n",
        "  n_per_epoch=n_per_epoch,\n",
        "  batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRenk9n_nWP",
        "colab_type": "text"
      },
      "source": [
        "To handle *OSError: [Errno 5]* while creating dataset,\n",
        "create subdirectories and relocate your images into subdirectories about 10,000 images per one folder.\n",
        "Or, maybe just re-run the shell to use cached data.\n",
        "Please, check [here](https://research.google.com/colaboratory/faq.html#drive-timeout) for the reason of error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YIWmowTY4pDY"
      },
      "source": [
        "# 2. Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc3M7aJo-k6d",
        "colab_type": "text"
      },
      "source": [
        "The stylizer model gets two inputs: contents and styles, and make stylized output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZigSwgIBW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "\n",
        "utils = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/utils.py')\n",
        "network = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/network.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_juI9UYNt0p",
        "colab_type": "text"
      },
      "source": [
        "Stylizer takes 2 input, a content image $c$ and a style image $s$,\n",
        "and generate a stylized image $g(t)$ with following steps.\n",
        "First, encode the images and make normalized feature $t$ using **adaptive instance normalization**.\n",
        "$$\n",
        "t = AdaIN(\\phi_L(c), \\phi_L(s))\n",
        "  = \\sigma(\\phi_L(s))(\\frac{\\phi_L(c) - \\mu(\\phi_L(c))}{\\sigma(\\phi_L(c))}) + \\mu(\\phi_L(s))\n",
        "$$\n",
        "where $\\phi_i$ is $i^{th}$ encoder, $L$ is number of encodings.\n",
        "Then, create new image from $t$ with decoder $g$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpH_QFvIQhre",
        "colab_type": "text"
      },
      "source": [
        "To train the model we need to define the loss function.\n",
        "The loss function is conposed with two different parts: style loss and content loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyqz_blbJDXf",
        "colab_type": "text"
      },
      "source": [
        "The style loss is calucalated as follows:\n",
        "$$\n",
        "L_{style}(s, g(t))=\n",
        "\\Sigma_{i=1}^L || \\mu( \\phi_i( g(t) ) ) - \\mu( \\phi_i( s ) ) ||_2\n",
        "+ \\Sigma_{i=1}^L || \\sigma( \\phi_i( g(t) ) ) - \\sigma( \\phi_i( s ) ) ||_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yexXvw8mIWRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_style_loss(x, epsilon=1e-5):\n",
        "  y_trues, y_preds = x\n",
        "  loss = [\n",
        "    utils.mse_loss(K.mean(y_true, axis=(1, 2)), K.mean(y_pred, axis=(1, 2)))\n",
        "    + utils.mse_loss(K.sqrt(K.var(y_true, axis=(1, 2)) + epsilon), K.sqrt(K.var(y_pred, axis=(1, 2)) + epsilon))\n",
        "    for y_true, y_pred in zip(y_trues, y_preds)\n",
        "  ]\n",
        "  return K.sum(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTtMWgkHLaPP",
        "colab_type": "text"
      },
      "source": [
        "The content loss is calucated as follows:\n",
        "$$\n",
        "L_{content}(t, g(t)) = || \\phi_L(g(t)) - t ||_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0CQhkfI8yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_content_loss(x):\n",
        "  y_true, y_pred = x\n",
        "  return utils.mse_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-DfFbv9TRL_",
        "colab_type": "text"
      },
      "source": [
        "The loss is weighted sum of the style loss and content loss.\n",
        "$$\n",
        "Loss = \\lambda_{style} \\cdot L_{style} + \\lambda_{content} \\cdot L_{content}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J1bUCFKRKxC",
        "colab_type": "text"
      },
      "source": [
        "Then, we can create a model. While training, we will fix the encoder's parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-gloqKf2vzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_trainer():\n",
        "\n",
        "  encoder = network.Encoder(input_shape=(crop_size, crop_size, 3), pretrained=True)\n",
        "  for l in encoder.layers:\n",
        "    l.trainable = False\n",
        "  adain = network.AdaIN(alpha=1.0)\n",
        "  decoder = network.Decoder(input_shape=encoder.output_shape[-1][1:])\n",
        "\n",
        "  content_input = Input(shape=(crop_size, crop_size, 3))\n",
        "  style_input = Input(shape=(crop_size, crop_size, 3))\n",
        "\n",
        "  content_features = encoder(content_input)\n",
        "  style_features = encoder(style_input)\n",
        "  normalized_feature = adain([content_features[-1], style_features[-1]])\n",
        "  generated = decoder(normalized_feature)\n",
        "\n",
        "  generated_features = encoder(generated)\n",
        "  content_loss = Lambda(calculate_content_loss, name='content_loss')([normalized_feature, generated_features[-1]])\n",
        "  style_loss = Lambda(calculate_style_loss, name='style_loss')([style_features, generated_features])\n",
        "  loss = Lambda(lambda x: content_weight * x[0] + style_weight * x[1], name='loss')([content_loss, style_loss])\n",
        "\n",
        "  trainer = Model(inputs=[content_input, style_input], outputs=[loss])\n",
        "  optim = optimizers.Adam(learning_rate=learning_rate)\n",
        "  trainer.compile(optimizer=optim, loss=lambda _, y_pred: y_pred)\n",
        "\n",
        "  return trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDreFlE2dazC",
        "colab_type": "text"
      },
      "source": [
        "To continue the learning process from the last epoch saved, check the directory,\n",
        "and if there are one or more trainer models, get the lastest one.\n",
        "Otherwise, create a trainer model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEwzFhShlNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = gdrive / model_dir\n",
        "trainer_name = 'trainer.epoch-{epoch}.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am25iqQ4n1Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_dir.exists():\n",
        "  model_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xAuUnIjovWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lastest_epoch = 0\n",
        "for candidate in model_dir.glob('*'):\n",
        "  if candidate.is_dir() or candidate.suffix != '.h5':\n",
        "    pass\n",
        "  print(candidate)\n",
        "  epoch = int(unformat_string(candidate.name, trainer_name)['epoch'])\n",
        "  if epoch > lastest_epoch:\n",
        "    lastest_epoch = epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvYmgnd4gD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lastest_epoch == 0:\n",
        "  trainer = make_trainer()\n",
        "else:\n",
        "  trainer = load_model(str(model_dir / trainer_name.format(epoch=lastest_epoch)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkshI008-QMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntI4Rq2-lp2",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qinYFaWu-odE",
        "colab_type": "text"
      },
      "source": [
        "Before begin to train, we need some callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15nTREEk-nGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeN-qoTV_4XI",
        "colab_type": "text"
      },
      "source": [
        "First callback is learning rate scheduler that decays the learning rate of optimizer.\n",
        "Second callback is for saving trainer every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvreBM32-yO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "  LearningRateScheduler(lambda epoch, _: learning_rate / (1.0 + learning_rate_decay * n_per_epoch * epoch)),\n",
        "  ModelCheckpoint(str(model_dir / trainer_name), save_freq='epoch')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fzs5-nFA5tn",
        "colab_type": "text"
      },
      "source": [
        "Now we can start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhRR9h08AThP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.fit_generator(dataset, epochs=epochs, workers=4, callbacks=callbacks, initial_epoch=lastest_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2Qyq2zHXgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}