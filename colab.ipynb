{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izp7T6LROH5p",
        "colab_type": "text"
      },
      "source": [
        "# AdaIN-Keras\n",
        "Keras implementation of [this paper](https://arxiv.org/abs/1703.06868) with [colab](https://colab.research.google.com/).\n",
        "Wrote by [KOSMOS](https://github.com/kukosmos), Korea University programming club.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1nMczBxSkjt",
        "colab_type": "text"
      },
      "source": [
        "You can run this code directly at [here](https://colab.research.google.com/github/kukosmos/adain-keras-2019/blob/master/colab.ipynb) using colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9np-E2Zp4e",
        "colab_type": "text"
      },
      "source": [
        "# 0. Settings & Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TdpU5ebiIDo",
        "colab_type": "text"
      },
      "source": [
        "You can specify the version of tensorflow to use with following command.\n",
        "Following command is the command to select the tensorflow 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1on6KQ-iOEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkBcPfq_URWD",
        "colab_type": "text"
      },
      "source": [
        "These are configurable variables that used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "892vltI4UkDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datas\n",
        "content_path = 'data/coco2017train'\n",
        "style_path = 'data/wikiart'\n",
        "image_size = 512\n",
        "crop_size = 256\n",
        "n_per_epoch = 1000\n",
        "batch_size = 8\n",
        "# loss\n",
        "style_weight = 10.0\n",
        "content_weight =  1.0\n",
        "# optimizer\n",
        "learning_rate = 1e-4\n",
        "learning_rate_decay = 5e-5\n",
        "# log\n",
        "model_dir = 'models/kaiser'\n",
        "# training\n",
        "epochs = 1280"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GHF3mg7byZr",
        "colab_type": "text"
      },
      "source": [
        "In this script we will use our implementation of helper methods and classes available in [github](https://github.com/kukosmos/adain-keras-2019)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqh6j5sYaAPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import types\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LDKMI1BaJt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# borrowed from https://stackoverflow.com/a/34491349\n",
        "def import_from_github(uri, name=None):\n",
        "  if not name:\n",
        "    name = os.path.basename(uri).lower().rstrip('.py')\n",
        "  \n",
        "  r = requests.get(uri)\n",
        "  r.raise_for_status()\n",
        "\n",
        "  codeobj = compile(r.content, uri, 'exec')\n",
        "  module = types.ModuleType(name)\n",
        "  exec(codeobj, module.__dict__)\n",
        "  return module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5OPnP1f3WEr",
        "colab_type": "text"
      },
      "source": [
        "This is method for help unformat the formatted string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_V1Sgq43Utk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hC40c2z3SfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# borrowed from https://stackoverflow.com/a/36838374\n",
        "def unformat_string(string, pattern):\n",
        "  regex = re.sub(r'{(.+?)}', r'(?P<_\\1>.+)', pattern)\n",
        "  values = list(re.search(regex, string).groups())\n",
        "  keys = re.findall(r'{(.+?)}', pattern)\n",
        "  return dict(zip(keys, values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMHmaj6PDcC",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k3X_V5RY6jL",
        "colab_type": "text"
      },
      "source": [
        "First, mount the google drive that contains the photos for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtwcHtP8OBl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyndpUoCYpMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0NQXhREYpCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive = Path('/content/drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xTG7R_NY8AL",
        "colab_type": "text"
      },
      "source": [
        "Before creating dataset, configure Pillow to handle errors while loading images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcS7AVuHcpy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrmDlDG0c3NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.MAX_IMAGE_PIXELS = None\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS9F6lQgdLxt",
        "colab_type": "text"
      },
      "source": [
        "Create dataset with content data and style data in your google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNBhjHpbN9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/dataloader.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJnJT2YZeY38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataloader.ContentStyleLoader(\n",
        "  content_root=gdrive / content_path,\n",
        "  content_image_shape=(image_size, image_size),\n",
        "  content_crop='random',\n",
        "  content_crop_size=crop_size,\n",
        "  style_root=gdrive / style_path,\n",
        "  style_image_shape=(image_size, image_size),\n",
        "  style_crop='random',\n",
        "  style_crop_size=crop_size,\n",
        "  n_per_epoch=n_per_epoch,\n",
        "  batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRenk9n_nWP",
        "colab_type": "text"
      },
      "source": [
        "To handle *OSError: [Errno 5]* while creating dataset,\n",
        "create subdirectories and relocate your images into subdirectories about 10,000 images per one folder.\n",
        "Or, maybe just re-run the shell to use cached data.\n",
        "Please, check [here](https://research.google.com/colaboratory/faq.html#drive-timeout) for the reason of error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YIWmowTY4pDY"
      },
      "source": [
        "# 2. Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc3M7aJo-k6d",
        "colab_type": "text"
      },
      "source": [
        "The stylizer model gets two inputs: contents and styles, and make stylized output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AZigSwgIBW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "\n",
        "utils = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/utils.py')\n",
        "network = import_from_github('https://raw.githubusercontent.com/kukosmos/adain-keras-2019/master/network.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_juI9UYNt0p",
        "colab_type": "text"
      },
      "source": [
        "Stylizer takes 2 input, a content image $c$ and a style image $s$,\n",
        "and generate a stylized image $g(t)$ with following steps.\n",
        "First, encode the images and make normalized feature $t$ using **adaptive instance normalization**.\n",
        "$$\n",
        "t = AdaIN(\\phi_L(c), \\phi_L(s))\n",
        "  = \\sigma(\\phi_L(s))(\\frac{\\phi_L(c) - \\mu(\\phi_L(c))}{\\sigma(\\phi_L(c))}) + \\mu(\\phi_L(s))\n",
        "$$\n",
        "where $\\phi_i$ is $i^{th}$ encoder, $L$ is number of encodings.\n",
        "Then, create new image from $t$ with decoder $g$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpH_QFvIQhre",
        "colab_type": "text"
      },
      "source": [
        "To train the model we need to define the loss function.\n",
        "The loss function is conposed with two different parts: style loss and content loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyqz_blbJDXf",
        "colab_type": "text"
      },
      "source": [
        "The style loss is calucalated as follows:\n",
        "$$\n",
        "L_{style}(s, g(t))=\n",
        "\\Sigma_{i=1}^L || \\mu( \\phi_i( g(t) ) ) - \\mu( \\phi_i( s ) ) ||_2\n",
        "+ \\Sigma_{i=1}^L || \\sigma( \\phi_i( g(t) ) ) - \\sigma( \\phi_i( s ) ) ||_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yexXvw8mIWRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_style_loss(x, epsilon=1e-5):\n",
        "  y_trues, y_preds = x\n",
        "  loss = [\n",
        "    utils.mse_loss(K.mean(y_true, axis=(1, 2)), K.mean(y_pred, axis=(1, 2)))\n",
        "    + utils.mse_loss(K.sqrt(K.var(y_true, axis=(1, 2)) + epsilon), K.sqrt(K.var(y_pred, axis=(1, 2)) + epsilon))\n",
        "    for y_true, y_pred in zip(y_trues, y_preds)\n",
        "  ]\n",
        "  return K.sum(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTtMWgkHLaPP",
        "colab_type": "text"
      },
      "source": [
        "The content loss is calucated as follows:\n",
        "$$\n",
        "L_{content}(t, g(t)) = || \\phi_L(g(t)) - t ||_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0CQhkfI8yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_content_loss(x):\n",
        "  y_true, y_pred = x\n",
        "  return utils.mse_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-DfFbv9TRL_",
        "colab_type": "text"
      },
      "source": [
        "The loss is weighted sum of the style loss and content loss.\n",
        "$$\n",
        "Loss = \\lambda_{style} \\cdot L_{style} + \\lambda_{content} \\cdot L_{content}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J1bUCFKRKxC",
        "colab_type": "text"
      },
      "source": [
        "Then, we can create a model. While training, we will fix the encoder's parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-gloqKf2vzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_trainer():\n",
        "\n",
        "  encoder = network.Encoder(input_tensor=Input(shape=(crop_size, crop_size, 3)))\n",
        "  for l in encoder.layers:\n",
        "    l.trainable = False\n",
        "  adain = network.AdaIN(alpha=1.0)\n",
        "  decoder = network.Decoder(name='decoder')\n",
        "\n",
        "  content_input = Input(shape=(crop_size, crop_size, 3), name='content_input')\n",
        "  style_input = Input(shape=(crop_size, crop_size, 3), name='style_input')\n",
        "\n",
        "  content_features = encoder(content_input)\n",
        "  style_features = encoder(style_input)\n",
        "  normalized_feature = adain([content_features[-1], style_features[-1]])\n",
        "  generated = decoder(normalized_feature)\n",
        "\n",
        "  generated_features = encoder(generated)\n",
        "  content_loss = Lambda(calculate_content_loss, name='content_loss')([normalized_feature, generated_features[-1]])\n",
        "  style_loss = Lambda(calculate_style_loss, name='style_loss')([style_features, generated_features])\n",
        "  loss = Lambda(lambda x: content_weight * x[0] + style_weight * x[1], name='loss')([content_loss, style_loss])\n",
        "\n",
        "  trainer = Model(inputs=[content_input, style_input], outputs=[loss])\n",
        "  optim = optimizers.Adam(learning_rate=learning_rate)\n",
        "  trainer.compile(optimizer=optim, loss=lambda _, y_pred: y_pred)\n",
        "\n",
        "  return trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDreFlE2dazC",
        "colab_type": "text"
      },
      "source": [
        "To continue the learning process from the last epoch saved, check the directory,\n",
        "and if there are one or more trainer models, get the lastest one.\n",
        "Otherwise, create a trainer model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeEwzFhShlNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = gdrive / model_dir\n",
        "trainer_name = 'trainer.epoch-{epoch}.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am25iqQ4n1Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_dir.exists():\n",
        "  model_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xAuUnIjovWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lastest_epoch = 0\n",
        "for candidate in model_dir.glob('*'):\n",
        "  if candidate.is_dir() or candidate.suffix != '.h5':\n",
        "    pass\n",
        "  print(candidate)\n",
        "  epoch = int(unformat_string(candidate.name, trainer_name)['epoch'])\n",
        "  if epoch > lastest_epoch:\n",
        "    lastest_epoch = epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvYmgnd4gD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lastest_epoch == 0:\n",
        "  trainer = make_trainer()\n",
        "else:\n",
        "  custom_layers = {\n",
        "    'Encoder': network.Encoder,\n",
        "    'AdaIN': network.AdaIN,\n",
        "    'Decoder': network.Decoder,\n",
        "    'ReflectionPad': network.ReflectionPad,\n",
        "    '<lambda>': lambda _, y_pred: y_pred\n",
        "  }\n",
        "  with CustomObjectScope(custom_layers):\n",
        "    trainer = load_model(str(model_dir / trainer_name.format(epoch=lastest_epoch)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkshI008-QMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntI4Rq2-lp2",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qinYFaWu-odE",
        "colab_type": "text"
      },
      "source": [
        "Before begin to train, we need some callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15nTREEk-nGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeN-qoTV_4XI",
        "colab_type": "text"
      },
      "source": [
        "First callback is learning rate scheduler that decays the learning rate of optimizer.\n",
        "Second callback is for saving trainer every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvreBM32-yO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "  LearningRateScheduler(lambda epoch, _: learning_rate / (1.0 + learning_rate_decay * n_per_epoch * epoch)),\n",
        "  ModelCheckpoint(str(model_dir / trainer_name), save_freq='epoch')\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fzs5-nFA5tn",
        "colab_type": "text"
      },
      "source": [
        "Now we can start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhRR9h08AThP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.fit_generator(dataset, epochs=epochs, workers=4, callbacks=callbacks, initial_epoch=lastest_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs140gIxuKId",
        "colab_type": "text"
      },
      "source": [
        "# 4. Reproduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KLtLLcIuSxJ",
        "colab_type": "text"
      },
      "source": [
        "To reproduce the images with our script, you need to extract the decoder weights from the trained model with this script.\n",
        "Following commands will extract the weights from trained model of the last epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2Qyq2zHXgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = model_dir / trainer_name.format(epoch=epochs)\n",
        "decoder_path = model_dir / 'decoder.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEpo22iKu8-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_layers = {\n",
        "  'Encoder': network.Encoder,\n",
        "  'AdaIN': network.AdaIN,\n",
        "  'Decoder': network.Decoder,\n",
        "  'ReflectionPad': network.ReflectionPad,\n",
        "  '<lambda>': lambda _, y_pred: y_pred\n",
        "}\n",
        "with CustomObjectScope(custom_layers):\n",
        "  model = load_model(str(model_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mThP8_EsvQB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_layer('decoder').save_weights(str(decoder_path), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-GDce1iBArF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
